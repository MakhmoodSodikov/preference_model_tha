{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T19:41:20.350290Z",
     "start_time": "2026-01-26T19:41:18.433735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from env.constants import ANTHROPIC_API_KEY"
   ],
   "id": "9546a1efc01f764c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparing async runner",
   "id": "288809d89dae2b77"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-26T19:41:22.159107Z",
     "start_time": "2026-01-26T19:41:21.494364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from run import run_research_agent_episode\n",
    "import pandas as pd\n",
    "from env.logger import get_logger\n",
    "import time\n",
    "import asyncio\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "async def run_single_in_thread(api_key, prompt, sem):\n",
    "    async with sem:\n",
    "        return await asyncio.to_thread(run_research_agent_episode, api_key, prompt)\n",
    "\n",
    "\n",
    "async def run_batch_async(api_key: str, prompt: str, num_runs: int = 10, max_concurrent: int = 10):\n",
    "    logger.info(f\"Running {num_runs} episodes. Max concurrent: {max_concurrent}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    sem = asyncio.Semaphore(max_concurrent)\n",
    "    tasks = [run_single_in_thread(api_key, prompt, sem) for _ in range(num_runs)]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    logger.info(f\"Total time: {total_time:.1f}s\")\n",
    "    return results"
   ],
   "id": "b8d63a760940b9bb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The `run_batch_async` function runs the agent in parallel and returns the results as a list of results (dicts), one for each episode. I used the asyncio.Semaphore to limit the number of concurrent processes at a time.",
   "id": "616cc65a86e848b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Start testing with small model (haiku-4-5)\n",
    "\n",
    "Running with env.constants.ANTHROPIC_MODEL = \"haiku-4-5\""
   ],
   "id": "144d9f4caf1e47d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import env\n",
    "from env.prompts import system_instruction_default, system_instruction_with_hints, system_instruction_with_hints_and_guidance\n",
    "\n",
    "env.constants.ANTHROPIC_MODEL"
   ],
   "id": "a10aa67787847f48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results = await run_batch_async(api_key=ANTHROPIC_API_KEY, prompt=system_instruction_default)",
   "id": "63c2b181a9663e36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "First, we try to check the quality and passing score for the `haiku-4-5` with the basic (default) system prompt, which is located in `env/prompts.py` and is designed to be a \"hard\" prompt - it doesn't give full information about the problem and doesn't include any instructions that help the agent to achieve better score.\n",
    "\n",
    "Some snippet of the main part of the default prompt:\n",
    "```markdown\n",
    "<...>\n",
    "Instruments:\n",
    "- You have {EXPERIMENTS_BUDGET} FLOPs for experiments. You have access to our `training_oracle` (a compute cluster).\n",
    "- Don't forget to check your budget with `check_available_resources`. Run as many experiments as needed.\n",
    "- Use `python` to perform math calculations.\n",
    "<...>\n",
    "```\n",
    "\n",
    "As you can see, the prompt doesn't include any hints or guidance, so the agent will have to solve the task by himself with minimum information available about the environment. The judge and reward function remains the same.\n"
   ],
   "id": "52fb489e76a572cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T17:28:30.023834Z",
     "start_time": "2026-01-26T17:28:29.916600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.json_normalize(results)\n",
    "success_rate = (df['verdict'] == 'SUCCESS').mean() * 100\n",
    "logger.info(f\"Success rate for {env.constants.ANTHROPIC_MODEL}: {success_rate}%\")"
   ],
   "id": "33b683d6792f2d54",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: Success rate for claude-haiku-4-5: 0.0%\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As expected, the success rate is 0%, because the environment is too hard for the agent.",
   "id": "8d9c75bcc5ae4bb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T17:28:33.910834Z",
     "start_time": "2026-01-26T17:28:33.883728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for r in results:\n",
    "\tlogger.info(r['reward_breakdown']['total_episode_reward'])"
   ],
   "id": "5ca5c96d0005ef01",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: 0.018\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.0277\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.0086\n",
      "==============================\n",
      "[INFO]: 0.0166\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's first help the model with hints in the prompt to achieve better success rate.\n",
    "\n",
    "I will be using `system_instruction_with_hints` prompt, which includes a few hints, more detailed description of the task and a hint how to solve it."
   ],
   "id": "39c66e404b3c1782"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results = await run_batch_async(api_key=ANTHROPIC_API_KEY, prompt=system_instruction_with_hints)",
   "id": "53e1baf7f308a077",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T17:48:12.770273Z",
     "start_time": "2026-01-26T17:48:12.592108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.json_normalize(results)\n",
    "success_rate = (df['verdict'] == 'SUCCESS').mean() * 100\n",
    "logger.info(success_rate)"
   ],
   "id": "dbe2e85e1b5b058d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: 0.0\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Still, result is 0% for the small model and even the improved is too hard for the haiku agent.\n",
    "\n",
    "But let's see the detailed reward breakdown for each episode:"
   ],
   "id": "cb9980cf8d9aee2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T17:48:18.126019Z",
     "start_time": "2026-01-26T17:48:18.097949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for r in results:\n",
    "\tlogger.info(r['reward_breakdown']['total_episode_reward'])"
   ],
   "id": "a635c97e01af3ca2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: 0.4305\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.1847\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.8497\n",
      "==============================\n",
      "[INFO]: 0.0729\n",
      "==============================\n",
      "[INFO]: 0.3158\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now we see that 7th episode was around 0.85 reward, which is almost the passing score. Moreover, other episodes' rewards are also much higher than before.\n",
    "\n",
    "Thus, we can approximate the result and assume that the passing score now is around ~10% for the model on a higher number of episodes."
   ],
   "id": "3d261c34d628139a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T17:58:21.862796Z",
     "start_time": "2026-01-26T17:58:21.848005Z"
    }
   },
   "cell_type": "code",
   "source": "logger.info(df['reward_breakdown.breakdown.total_behaviour_reward'])",
   "id": "5aeb0468717c7449",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: 0     True\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "4     True\n",
      "5     True\n",
      "6     True\n",
      "7     True\n",
      "8     True\n",
      "9    False\n",
      "Name: reward_breakdown.breakdown.total_behaviour_reward, dtype: bool\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Even if all the episodes formally failed (since they are <85% reward rate), model worked out much better this time, compared to the first run. If we change the reward threshold to 80%, we will see 10% success rate, which is good to go start the agent training using PPO or other RL frameworks.\n",
    "\n",
    "However, in some cases it even failed the behavioural tests, such as budget exhausting and hallucinations (didn't call oracle or didn't use the python tooling).\n",
    "\n",
    "Now let's run the experiment with even easier prompt, that includes all the guidance techniques, and pushes the model towards checking the budget everytime and pay attention to the final budget constraint $C = 6 * N * D$"
   ],
   "id": "b1d6b8883c343924"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results = await run_batch_async(api_key=ANTHROPIC_API_KEY, prompt=system_instruction_with_hints_and_guidance)",
   "id": "4d3700b307c9ba6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T18:39:13.766661Z",
     "start_time": "2026-01-26T18:39:13.656012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.json_normalize(results)\n",
    "success_rate = (df['verdict'] == 'SUCCESS').mean() * 100\n",
    "logger.info(success_rate)"
   ],
   "id": "316c50bd75d87974",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: 0.0\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T18:39:15.870587Z",
     "start_time": "2026-01-26T18:39:15.831074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logger.info(success_rate)\n",
    "for r in results:\n",
    "\tlogger.info(r['reward_breakdown']['total_episode_reward'])"
   ],
   "id": "1b432a7c3f3eceb8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.4379\n",
      "==============================\n",
      "[INFO]: 0.8195\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.0204\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.1172\n",
      "==============================\n",
      "[INFO]: 0.1837\n",
      "==============================\n",
      "[INFO]: 0.2367\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Results didn't improve sufficiently, so we may assume that we reached the capability of the agetn itself (`haiku-4-5` LLM model).",
   "id": "e8274c82c040f5c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Running bigger model (sonnet-4-5)\n",
    "\n",
    "Running with ANTHROPIC_MODEL = \"claude-sonnet-4-5-20250929\""
   ],
   "id": "71029fd0276428f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T18:40:00.873451Z",
     "start_time": "2026-01-26T18:40:00.832063Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'claude-sonnet-4-5-20250929'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3,
   "source": [
    "import env\n",
    "from env.prompts import system_instruction_default\n",
    "\n",
    "env.constants.ANTHROPIC_MODEL"
   ],
   "id": "888c29d356a6e28d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now let's try to check how bigger models will react to this environment.\n",
    "\n",
    "I decided to go with `claude-sonnet-4-5`'s latest version."
   ],
   "id": "d33bc76cceb128f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results = await run_batch_async(api_key=ANTHROPIC_API_KEY, prompt=system_instruction_default)",
   "id": "cc9a05791c9a2fd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T18:49:22.887439Z",
     "start_time": "2026-01-26T18:49:22.743190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.json_normalize(results)\n",
    "success_rate = (df['verdict'] == 'SUCCESS').mean() * 100\n",
    "logger.info(success_rate)"
   ],
   "id": "8757bfed18c70abb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: 0.0\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T18:50:10.248903Z",
     "start_time": "2026-01-26T18:50:10.146801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logger.info(success_rate)\n",
    "for r in results:\n",
    "\tlogger.info(r['reward_breakdown']['total_episode_reward'])"
   ],
   "id": "2dda8a1339879a2c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.0993\n",
      "==============================\n",
      "[INFO]: 0.0088\n",
      "==============================\n",
      "[INFO]: 0.4446\n",
      "==============================\n",
      "[INFO]: 0.026\n",
      "==============================\n",
      "[INFO]: 0.0949\n",
      "==============================\n",
      "[INFO]: 0.0\n",
      "==============================\n",
      "[INFO]: 0.5984\n",
      "==============================\n",
      "[INFO]: 0.0806\n",
      "==============================\n",
      "[INFO]: 0.5781\n",
      "==============================\n",
      "[INFO]: 0.7332\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T18:51:25.342978Z",
     "start_time": "2026-01-26T18:51:25.251590Z"
    }
   },
   "cell_type": "code",
   "source": "logger.info(df['reward_breakdown.breakdown.total_behaviour_reward'])",
   "id": "1fed0841e1ebde22",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: 0    True\n",
      "1    True\n",
      "2    True\n",
      "3    True\n",
      "4    True\n",
      "5    True\n",
      "6    True\n",
      "7    True\n",
      "8    True\n",
      "9    True\n",
      "Name: reward_breakdown.breakdown.total_behaviour_reward, dtype: bool\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, we see that even for the \"hard\" prompt model didn't fail the kill switch judge checks, resulting in pretty high rewards for some episodes, comparably similar to `haiku-4-5`'s best result on the \"easy\" prompts.\n",
    "\n",
    "Let's try to run the environment with advanced prompt with small hints and little guidance instructions:"
   ],
   "id": "e223d6e8ccd1c0f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results = await run_batch_async(api_key=ANTHROPIC_API_KEY, prompt=system_instruction_with_hints)",
   "id": "b0fc743f77018f37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T19:00:31.820197Z",
     "start_time": "2026-01-26T19:00:31.730338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.json_normalize(results)\n",
    "success_rate = (df['verdict'] == 'SUCCESS').mean() * 100\n",
    "logger.info(success_rate)"
   ],
   "id": "f4bbaaffcba53e1a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: 50.0\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T19:02:16.684821Z",
     "start_time": "2026-01-26T19:02:16.592215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for r in results:\n",
    "\tlogger.info(r['reward_breakdown']['total_episode_reward'])"
   ],
   "id": "caa1a4b415af97ca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: 0.5917\n",
      "==============================\n",
      "[INFO]: 0.903\n",
      "==============================\n",
      "[INFO]: 0.1143\n",
      "==============================\n",
      "[INFO]: 0.9705\n",
      "==============================\n",
      "[INFO]: 0.445\n",
      "==============================\n",
      "[INFO]: 0.9814\n",
      "==============================\n",
      "[INFO]: 0.5726\n",
      "==============================\n",
      "[INFO]: 0.6836\n",
      "==============================\n",
      "[INFO]: 0.9793\n",
      "==============================\n",
      "[INFO]: 1.0\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now it seems optimal for bigger model and we see good reward figures and success rate of 50%, which is good-to-start rate for the PPO training/fine-tuning of the agent.\n",
    "\n",
    "Now let's try to run the environment with even more advanced prompt with full guidance instructions:"
   ],
   "id": "37effb7445d9b76c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results = await run_batch_async(api_key=ANTHROPIC_API_KEY, prompt=system_instruction_with_hints_and_guidance)",
   "id": "4a5517bea35e1a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T19:57:34.046629Z",
     "start_time": "2026-01-26T19:57:33.934960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.json_normalize(results)\n",
    "success_rate = (df['verdict'] == 'SUCCESS').mean() * 100\n",
    "logger.info(success_rate)"
   ],
   "id": "e5de77bf670fd194",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: 70.0\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T19:57:41.007664Z",
     "start_time": "2026-01-26T19:57:40.959303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for r in results:\n",
    "\tlogger.info(r['reward_breakdown']['total_episode_reward'])"
   ],
   "id": "56f8922d7371eb56",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: 0.5461\n",
      "==============================\n",
      "[INFO]: 0.9086\n",
      "==============================\n",
      "[INFO]: 0.994\n",
      "==============================\n",
      "[INFO]: 0.9603\n",
      "==============================\n",
      "[INFO]: 1.0\n",
      "==============================\n",
      "[INFO]: 0.9889\n",
      "==============================\n",
      "[INFO]: 0.75\n",
      "==============================\n",
      "[INFO]: 0.984\n",
      "==============================\n",
      "[INFO]: 0.7246\n",
      "==============================\n",
      "[INFO]: 1.0\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Finally, we see that agent outperformed the task with 70% success rate, when we almost gave him the full solution and step-by-step guidance in the prompt. Even though the model is not perfect, so it's possible to fine-tune it further.\n",
    "\n",
    "And at the same point, prompt appears to be close to complete guided instruction and further prompt enhancing will just lead to desired behaviour pursuing or data leakage in the prompt. It's almost impossible to optimize the prompt without adding more hints that will limit model's freedom."
   ],
   "id": "693f1c01ecf2a668"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c052f40da8eff4a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
